diff --git a/makedumpfile.c b/makedumpfile.c
index 78c5b45..21ff870 100644
--- a/makedumpfile.c
+++ b/makedumpfile.c
@@ -52,7 +52,7 @@ static unsigned long long	write_bytes;
 
 static void first_cycle(mdf_pfn_t start, mdf_pfn_t max, struct cycle *cycle)
 {
-	cycle->start_pfn = round(start, info->pfn_cyclic);
+	cycle->start_pfn = MAX(start, round(start, info->pfn_cyclic));
 	cycle->end_pfn = cycle->start_pfn + info->pfn_cyclic;
 
 	if (cycle->end_pfn > max)
@@ -6807,6 +6807,9 @@ create_2nd_bitmap(struct cycle *cycle)
 	 */
 	exclude_nodata_pages(cycle);
 
+	if (cycle->flags & MRF_MANDATORY)
+		goto skip_and_sync;
+
 	/*
 	 * Exclude cache pages, cache private pages, user data pages,
 	 * and hwpoison pages.
@@ -6866,6 +6869,7 @@ create_2nd_bitmap(struct cycle *cycle)
 		}
 	}
 
+skip_and_sync:
 	if (!sync_2nd_bitmap())
 		return FALSE;
 
@@ -9143,6 +9147,142 @@ write_kdump_bitmap2(struct cycle *cycle) {
 	}
 }
 
+#define COMMAND_LINE_SIZE 2048
+#define proccmdline "./proc/cmdline"
+static ulong get_per_cpu_offset()
+{
+        FILE *fp;
+        ulong per_cpu_offset_addr = 0;
+        char cmdline[COMMAND_LINE_SIZE], *ptr, *end;
+        memset(cmdline, 0, COMMAND_LINE_SIZE);
+
+
+        fp = fopen(proccmdline, "r"); 
+        if (!fp) {
+                ERRMSG("Cannot open %s\n", proccmdline);
+                return 0;
+        }
+        if (fgets(cmdline, sizeof(cmdline), fp) != 0)
+        {
+                ptr = strstr(cmdline, "core_pcpu_off=");
+                if (!ptr)
+                        return 0;
+
+                ptr += strlen("core_pcpu_off=");
+                per_cpu_offset_addr = strtoull(ptr, &end, 16);
+        }
+
+        return per_cpu_offset_addr;
+}
+/* 
+ * x86_64 implemention.
+ */
+int get_per_cpu_size_offset(int *pcpu_size, unsigned long *pcpu_offset)
+{
+	ulong addr = 0;
+	unsigned long pcpu_offsets[2]; // CPU0 and CPU1
+	if (!readmem(VADDR, 0xffffffffb863cba0, pcpu_offsets, sizeof(pcpu_offsets))) {
+			ERRMSG("Can't read __per_cpu_offset from vmcore memory.\n");
+			return FALSE;
+		}
+
+		ERRMSG("Can't read __per_cpu_offset from vmcore memory %lx %lx.\n", pcpu_offsets[1], pcpu_offsets[0]);
+		*pcpu_size = pcpu_offsets[1] - pcpu_offsets[0];
+		*pcpu_offset = pcpu_offsets[0];
+		return TRUE;
+	}
+
+/*
+	if (SYMBOL(__per_cpu_offset) != NOT_FOUND_SYMBOL) {
+		addr = SYMBOL(__per_cpu_offset);
+
+	} else {
+		addr = get_per_cpu_offset();
+		ERRMSG("Symbol __per_cpu_offset isn't found.\n");
+	}
+	if (addr) {
+		if (!readmem(VADDR, addr, pcpu_offsets, sizeof(pcpu_offsets))) {
+			ERRMSG("Can't read __per_cpu_offset from vmcore memory.\n");
+			return FALSE;
+		}
+		*pcpu_size = pcpu_offsets[1] - pcpu_offsets[0];
+		*pcpu_offset = pcpu_offsets[0];
+		return TRUE;
+	}
+*/
+	return FALSE;
+}
+
+/*
+ * x86_64
+ * x = y + ((x > y) ? phys_base : (__START_KERNEL_map - PAGE_OFFSET));
+ */
+unsigned long __phys_addr(unsigned long va)
+{
+        unsigned long pa;
+
+	if (va > __START_KERNEL_map) {
+		pa = va - __START_KERNEL_map + info->phys_base;
+	} else {
+		pa = va - info->page_offset;
+	}
+
+        return pa;
+}
+
+int get_per_cpu_memory_range(struct mem_range *mr)
+{
+	int rv;
+	int pcpu_size;
+	unsigned long pcpu_offset;
+	int cpus = get_nr_cpus();
+
+	rv = get_per_cpu_size_offset(&pcpu_size, &pcpu_offset);
+	if (rv != TRUE) {
+		ERRMSG("Can't get __per_cpu_offset info.\n");
+		return FALSE;
+	}
+
+	mr->start = __phys_addr(pcpu_offset);
+	mr->end = __phys_addr(pcpu_offset + cpus * pcpu_size);
+
+	return TRUE;
+}
+
+void init_memory_range(struct mem_range *mr, unsigned long s, 
+			unsigned long e, unsigned flags)
+{
+	mr->start = s;
+	mr->end = e;
+	mr->start_pfn = paddr_to_pfn(s);
+	mr->end_pfn = paddr_to_pfn(roundup(e, PAGESIZE()));
+	mr->flags = flags;
+}
+/*
+ * [0]: 0 - per_cpu_start;
+ * [1]: per_cpu_start - per_cpu_end;
+ * [2]: per_cpu_end - maxpfn;
+ */
+int initialize_memory_ranges(struct mem_range *mr)
+{
+	int rv;
+	struct mem_range pcpu_mr;
+
+	rv = get_per_cpu_memory_range(&pcpu_mr);
+
+	if (rv != TRUE) {
+		init_memory_range(&mr[0], 0, info->max_mapnr * PAGESIZE(), 0);
+		return FALSE;
+	}
+
+	init_memory_range(&mr[0], 0, pcpu_mr.start, 0);
+	init_memory_range(&mr[1], pcpu_mr.start, pcpu_mr.end, MRF_MANDATORY);
+	init_memory_range(&mr[2], pcpu_mr.end, info->max_mapnr * PAGESIZE(), 0);
+ERRMSG("read __per_cpu_offset from vmcore memory %lx %lx %lx.\n", pcpu_mr.start, pcpu_mr.end, info->max_mapnr);
+
+	return TRUE;
+}
+
 int
 write_kdump_pages_and_bitmap_cyclic(struct cache_data *cd_header, struct cache_data *cd_page)
 {
@@ -9204,30 +9344,47 @@ write_kdump_pages_and_bitmap_cyclic(struct cache_data *cd_header, struct cache_d
 			return FALSE;
 	}
 
+	/*
+	 * Initialize physcial memory ranges.
+	 */
+	int nr_ranges= 3;
+	struct mem_range mr[nr_ranges];
+	if (!initialize_memory_ranges(mr)) {
+		nr_ranges = 1;
+	}
+
 	/*
 	 * Write pages and bitmap cyclically.
 	 */
-	//cycle = {0, 0};
-	memset(&cycle, 0, sizeof(struct cycle));
-	for_each_cycle(0, info->max_mapnr, &cycle)
+	for (int i = 0; i < nr_ranges; i++) 
 	{
-		if (info->flag_cyclic) {
-			if (!create_2nd_bitmap(&cycle))
-				return FALSE;
-		}
-
-		if (!write_kdump_bitmap2(&cycle))
-			return FALSE;
+		mdf_pfn_t start = mr[i].start_pfn;
+		mdf_pfn_t end = mr[i].end_pfn;
+		//cycle = {0, 0};
+		memset(&cycle, 0, sizeof(struct cycle));
+		cycle.flags = mr[i].flags;
+ERRMSG("cycle %lx %lx %lx.\n", start, end, cycle.flags);
+		for_each_cycle(start, end, &cycle)
+		{
+ERRMSG("per cycle %lx %lx %lx.\n", cycle.start_pfn, cycle.end_pfn, cycle.flags);
+			if (info->flag_cyclic) {
+				if (!create_2nd_bitmap(&cycle))
+					return FALSE;
+			}
 
-		if (info->num_threads) {
-			if (!write_kdump_pages_parallel_cyclic(cd_header,
-							cd_page, &pd_zero,
-							&offset_data, &cycle))
-				return FALSE;
-		} else {
-			if (!write_kdump_pages_cyclic(cd_header, cd_page, &pd_zero,
-					&offset_data, &cycle))
+			if (!write_kdump_bitmap2(&cycle))
 				return FALSE;
+
+			if (info->num_threads) {
+				if (!write_kdump_pages_parallel_cyclic(cd_header,
+								cd_page, &pd_zero,
+								&offset_data, &cycle))
+					return FALSE;
+			} else {
+				if (!write_kdump_pages_cyclic(cd_header, cd_page, &pd_zero,
+						&offset_data, &cycle))
+					return FALSE;
+			}
 		}
 	}
 	free_bitmap2_buffer();
diff --git a/makedumpfile.h b/makedumpfile.h
index 5125c5e..2b22792 100644
--- a/makedumpfile.h
+++ b/makedumpfile.h
@@ -2137,6 +2137,19 @@ struct memory_range {
 	unsigned long long start, end;
 };
 
+#define MRF_MANDATORY		(0x1 << 0)
+#define MRF_EXCLUDED		(0x1 << 1)
+
+#define MRT_PERCPU		0x1
+struct mem_range {
+	unsigned long long start;
+	unsigned long long end;
+	unsigned long start_pfn;
+	unsigned long end_pfn;
+	unsigned long long flags;
+	int type;
+};
+
 #define CRASH_RESERVED_MEM_NR   8
 extern struct memory_range crash_reserved_mem[CRASH_RESERVED_MEM_NR];
 extern int crash_reserved_mem_nr;
@@ -2312,6 +2325,7 @@ struct cycle {
 	mdf_pfn_t exclude_pfn_start;
 	mdf_pfn_t exclude_pfn_end;
 	mdf_pfn_t *exclude_pfn_counter;
+	unsigned long long flags;
 };
 
 static inline int
