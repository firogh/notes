# Observability
crash> dev -d | head
MAJOR GENDISK            NAME       REQUEST_QUEUE      TOTAL ASYNC  SYNC   DRV 
request_queue.nr_rqs includes request_queue.in_flight
## requests queued in request queue
request_queue.rq or root_rl
request_queue.nr_rqs: removed in latest kernel.
get_request and blk_finish_request
for mq: blk_mq_ctx.rq_dispatched and blk_mq_ctx.rq_completed
rq counts including following in_flight counts.
## request_queue.in_flight: requests sent to drv
blk_dequeue_request & RQF_STARTED both in blk_peek_request
q->in_flight[rq_is_sync(rq)]++;
__blk_put_request => elv_completed_request and elv_requeue_request
q->in_flight[rq_is_sync(rq)]--

# Filesystem
[KS2008: Filesystem and block layer interaction](https://lwn.net/Articles/298589/)

# Units
page, block, sector
bio->bi_iter.bi_sector = bh->b_blocknr * (bh->b_size >> 9);	# sector_nr = blocknr * (block_size / 512)

# Buffer head
commit 205f87f6b342444f722e4559d33318686f7df2ca
Refs: v2.6.16-2980-g205f87f6b342
Author:     Badari Pulavarty <pbadari@us.ibm.com>
AuthorDate: Sun Mar 26 01:38:00 2006 -0800
Commit:     Linus Torvalds <torvalds@g5.osdl.org>
CommitDate: Sun Mar 26 08:57:01 2006 -0800
    [PATCH] change buffer_head.b_size to size_t
- * Keep related fields in common cachelines.  The most commonly accessed
- * field (b_state) goes at the start so the compiler does not generate
- * indexed addressing for it.
+ * Historically, a buffer_head was used to map a single block
+ * within a page, and of course as the unit of I/O through the
+ * filesystem and block layers.  Nowadays the basic I/O unit
+ * is the bio, and buffer_heads are used for extracting block			# 1. extracting block mappings (via a get_block_t call)
+ * mappings (via a get_block_t call), for tracking state within		# 2. tracking state within a page (via a page_mapping) 
+ * a page (via a page_mapping) and for wrapping bio submission			# 3. wrapping bio submission for backward compatibility reasons 
+ * for backward compatibility reasons (e.g. submit_bh).
[LKD3: The Old Versus the New at stackoverflow](https://stackoverflow.com/a/57407020/1025001)
[Is nobh code still useful?](http://linux-kernel.2935.n7.nabble.com/Is-nobh-code-still-useful-td509649.html)
[Linus on Buffer head](https://yarchive.net/comp/linux/buffer_heads.html)
[The buffer_head api that used to give you access to the buffer cache, now gives you access to the page cache for the block device.](https://lwn.net/Articles/712467/)
[Large pages, large blocks, and large problems](https://lwn.net/Articles/250335/)
[Large block size support](https://lwn.net/Articles/232757/)
[History: LDD2: How does buffer_head work with request struct: ](https://www.xml.com/ldd/chapter/book/ch12.html#t4)
## Translation
__getblk_slow, grow_buffers, grow_dev_page, alloc_page_buffers
__getblk_gfp -> grow_dev_page -> buffer cache
__bread_gfp -> __getblk_gfp and submit_bh
__ext4_iget -> __ext4_get_inode_loc -> sb_getblk
Is BUFFER_FNS BUFFER_FUNCTIONS?
ext4_write_inode
## BH_delay
16:53大疆创新李磊 阿克曼
@杨永明 Firo 延迟分配，可以减少多进程同时写文件造成文件碎片
设想一个场景，两个进程pa,pb同时追加写文件，如果直接申请块就马上给的话，就会出现pa申请的block在1,3,5……
pb申请的block在2,4，6……
bh_delayn推迟块的分配时机到回写时候进行。这样pa和pb就能分别获取连续的物理块
[[RFC] basic delayed allocation in VFS](https://linux-fsdevel.vger.kernel.narkive.com/bGiQumkf/rfc-basic-delayed-allocation-in-vfs)

# Block buffer write
commit 090da37209e13c26f3723e847860e9f7ab23e113
Author:     Andrew Morton <akpm@zip.com.au>
AuthorDate: Mon Apr 29 23:52:10 2002 -0700
Commit:     Linus Torvalds <torvalds@home.transmeta.com>
CommitDate: Mon Apr 29 23:52:10 2002 -0700
    [PATCH] writeback from address spaces
+ * The generic ->writepage function for buffer-backed address_spaces
 int block_write_full_page(struct page *page, get_block_t *get_block)

# bio
[A block layer introduction part 1: the bio layer](https://lwn.net/Articles/736534/)
[Lwn: Driver porting: the BIO structure](https://lwn.net/Articles/26404/)
[Jens Axobe's papper: Linux Block IO—present and future](https://www.landley.net/kdocs/ols/2004/ols2004v1-pages-51-62.pdf)
[Jens Axobe: Notes on the Generic Block Layer Rewrite in Linux 2.5](https://www.kernel.org/doc/Documentation/block/biodoc.txt)
[Notes on 2.5 block i/o layer changes](http://lse.sourceforge.net/io/bionotes.txt)
bi_io_vec - bio_vec
Documentation/block/biovecs.txt
bi_iter - bvec_iter 
block: Abstract out bvec iterator - 4f024f3797c43cb4b73cd2c50cec728842d0e49e
## bi_sector
submit_bio -> generic_make_request -> generic_make_request_checks -> blk_partition_remap
tglx: commit e1e2cfc3fb42dbe54dd94fe97ba17a62cd7a265b
Author: Linus Torvalds <torvalds@athlon.transmeta.com>
Date:   Mon Feb 4 23:58:06 2002 -0800
    v2.5.0.1 -> v2.5.0.2
    - Jens Axboe: start of new block IO layer
- * generic_make_request and the drivers it calls may use b_reqnext,
- * and may change b_rdev and b_rsector.  So the values of these fields
+ * generic_make_request and the drivers it calls may use bi_next if this
+ * bio happens to be merged with someone else, and may change bi_dev and
+ * bi_rsector for remaps as it sees fit.  So the values of these fields
  * should NOT be depended on after the call to generic_make_request.
- * Because of this, the caller should record the device address
- * information in b_dev and b_blocknr.
  *
- * Apart from those fields mentioned above, no other fields, and in
- * particular, no other flags, are changed by generic_make_request or
- * any lower level drivers.
  * */
-void generic_make_request (int rw, struct buffer_head * bh)
## merge bio
all bios in same request is contiguous.
__make_request elv_merge
/sys/block/sda/queue/max_sectors_kb 1280??
Front merge, Back merge, Coalesce merge

## End bio callback
__bread_slow: b_end_io = end_buffer_read_sync
__bread_slow->submit_bh -> submit_bh_wbc: bio->bi_end_io = end_bio_bh_io_sync
callback: bio_endio end_bio_bh_io_sync

## submit_bio
blk_queue_bio
Case 1. Try Merge 
1.1 Plug merge
1.2 Elevator merge; CFS, deadline, noop
Case 2. Plug 
2.1 full? blk_flush_plug_list
2.2 list_add_tail

# Request layer
make_request_fn: blk_queue_bio
[Block layer introduction part 2: the request layer](https://lwn.net/Articles/738449/)
[Driver porting: Request Queues I](https://lwn.net/Articles/27055/)
[Driver porting: Request Queues II](https://lwn.net/Articles/27361/)
request_queue, blk_init_queue, queue_head: linked list of request
/sys/block/sda/queue/nr_requests
request_fn: interfece between block layer and device for read or write
make_request_fn: transform bio to request.
generic_make_request
convert sector from partition to gendisk

## REQ Barrier
tglx:   commit 719eb3e1860791195ed7656b800d8bb57b277a75
Author:     Jens Axboe <axboe@suse.de>
AuthorDate: Thu Nov 7 21:50:01 2002 -0800
Commit:     Jens Axboe <axboe@suse.de>
CommitDate: Thu Nov 7 21:50:01 2002 -0800
    [PATCH] soft and hard barriers
    Right now we have one type of barrier in the block layer, and that is
    used mainly for making sure that the io scheduler doesn't reorder
    requests when we don't want it to.  We also need a flag to tell the io
    scheduler and low level queue that this is a barrier.  So basically two
    needs:
    o software barrier, prevents the io scheduler from reordering
    o hardware barrier, driver must prevent drive from reordering
    So this patch gets rid of REQ_BARRIER and instead adds REQ_SOFTBARRIER
    and REQ_HARDBARRIER.
## Timeline
### RQF_STARTED
https://bugzilla.suse.com/show_bug.cgi?id=930934
The warnings from blk_complete_request() about request not having REQ_STARTED which are before the BUG_ON triggering are actually reporting that someone is queueing completion of a request that hasn't been run. So they are warning about problems that are coming.

# IO scheduler
elv_iosched_show, elv_register
/sys/block/sda/queue/scheduler

# Blk flush
generic_file_fsync blkdev_issue_flush
case 1 schedule
kblockd_workqueue -> blk_delay_work
case 2 
_blk_run_queue -> q->request_fn scsi_request_fn
## bio_list
Recursion avoidance
queue bio before make_request_fn
## Submit request to driver
__blk_run_queue -> request_fn scsi_request_fn

# Blk-mq
[The multiqueue block layer](https://lwn.net/Articles/552904/)
[Kernel Recipes 2015 - Solving the Linux storage scalability bottlenecks - by Jens Axboe](https://www.youtube.com/watch?v=VIdKBD9-Ozg&t=110s)
[Linux Block IO: Introducing Multi-queue SSD Access on Multi-core Systems](https://kernel.dk/systor13-final18.pdf)
commit 320ae51feed5c2f13664aa05a76bec198967e04d
Refs: v3.12-rc5-9-g320ae51feed5
Author:     Jens Axboe <axboe@kernel.dk>
AuthorDate: Thu Oct 24 09:20:05 2013 +0100
Commit:     Jens Axboe <axboe@kernel.dk>
CommitDate: Fri Oct 25 11:56:00 2013 +0100
    blk-mq: new multi-queue block IO queueing mechanism

# Completion
scsi_end_request
blk_finish_request
__blk_mq_end_request

scsi_end_request+0x116/0x1e0
scsi_io_completion+0x168/0x6a0
scsi_finish_command+0xdc/0x140
scsi_softirq_done+0x132/0x160
blk_done_softirq+0x96/0xc0

   1551 -1875536096) end_bio_bh_io_sync
    977 -1874807536) ext4_end_bio
    136 -1874805104) mpage_end_io
     66 -1874069824) submit_bio_wait_endio

 => submit_bio_wait
 => blkdev_issue_flush
 => ext4_sync_file
 => do_fsync
 => __x64_sys_fdatasync
 => do_syscall_64
